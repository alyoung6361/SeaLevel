{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2017 The University of Sydney, Australia\n",
    "This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License, version 2, as published by the Free Software Foundation.\n",
    "\n",
    "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License along with this program; if not, write to Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n",
    "\n",
    "Authors: John Cannon and Simon Williams\n",
    "\n",
    "### This notebook extracts subduction zone and mid-ocean ridge segments from the tecontic reconstruction model and samples them at regularly spaced intervals. For each point on the sz segment plate age and velocity are extracted. For each point on the mor segment velocity is extracted.\n",
    "\n",
    "##### Input:\n",
    "\n",
    "GPlates reconstructed topological plate boundaries\n",
    "\n",
    "Sea floor age grids\n",
    "\n",
    "##### Output:\n",
    "\n",
    "file of time-dependent subduction zone kinematics and plate ages e.g. szData_summaryStats_NNRPlateModel.csv\n",
    "\n",
    "file of  time-dependent mor kinematics e.g. morData_summaryStats_NNRPlateModel.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/ajy321/pygplates_rev18_python27_MacOS64')\n",
    "import pygplates\n",
    "# Add directory containing the 'ptt' module (Plate Tectonic Tools) to the Python path.\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as spi\n",
    "import numpy as np\n",
    "os.chdir('/Users/ajy321/PhD_work/SeaLevel/SeaLevel_MS/PythonNotebooks/PlateTectonicTools')\n",
    "import subduction_convergence\n",
    "import ridge_spreading_rate\n",
    "\n",
    "\n",
    "root = '/Users/ajy321/PhD_work/SeaLevel/SeaLevel_MS/GPlatesFiles/'\n",
    "\n",
    "# Input rotation and topology files.\n",
    "rotation_filename = [root+'1000-410_rotations-NNR.rot', \n",
    "                     root+'Global_EB_250-0Ma_GK07_2017-NNR.rot', \n",
    "                     root+'Global_EB_410-250Ma_GK07_2017-NNR.rot', \n",
    "                     root+'NR_0Ma_1000Ma_for_gplates.rot']\n",
    "\n",
    "rotation_model = pygplates.RotationModel(rotation_filename)\n",
    "\n",
    "topology_filenames = [root+'1000-410-Convergence-NNR.gpml', \n",
    "                      root+'1000-410-Divergence-NNR.gpml', \n",
    "                      root+'1000-410-Topologies-NNR.gpml', \n",
    "                      root+'1000-410-Transforms-NNR.gpml', \n",
    "                      root+'Global_EarthByte_Mesozoic-Cenozoic_plate_boundaries_2016_v5-NNR.gpml', \n",
    "                      root+'Global_EarthByte_Paleozoic_plate_boundaries_2016_v5-NNR.gpml', \n",
    "                      root+'TopologyBuildingBlocks_AREPS-NNR.gpml']\n",
    "\n",
    "# Output file containing results at each reconstruction time.\n",
    "output_filename = 'output.txt'\n",
    "\n",
    "# Base filename and extension of raster to sample.\n",
    "raster_filename_base ='/Users/ajy321/PhD_work/SeaLevel/SeaLevel_MS/GPlatesFiles/AgeGrids/agegrid_masked'\n",
    "raster_filename_ext = 'nc'\n",
    "\n",
    "# Define the time range.\n",
    "# The reconstruction time range (topologies resolved to these times).\n",
    "# Also used to get paleo raster filenames based on 'raster_filename_base'.\n",
    "min_time = 0\n",
    "max_time = 580\n",
    "time_step = 20\n",
    "# Tessellate the subduction zones to 0.5 degrees.\n",
    "tessellation_threshold_radians = math.radians(0.5)\n",
    "\n",
    "# name the model what you want.\n",
    "model='NNRPlateModel'\n",
    "\n",
    "# set working directory and make if it does not exist\n",
    "workDir=\"/Users/ajy321/PhD_work/SeaLevel/SeaLevel_MS/PythonNotebooks/DeepwaterCycling\"\n",
    "if not os.path.exists(workDir):\n",
    "    os.makedirs(workDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a program to sample grids\n",
    "# The method used here for sampling of masked (NaN) rasters is faster than using the 'raster_query' module.\n",
    "\n",
    "try:\n",
    "    from netCDF4 import Dataset as netcdf\n",
    "except ImportError:\n",
    "    from scipy.io import netcdf_file as netcdf\n",
    "    print('Warning: NetCDF4 grids not supported (\"netCDF4\" Python module not found). '\n",
    "          'Falling back to NetCDF3, rasters may fail to load.', file=sys.stderr)\n",
    "\n",
    "import scipy.interpolate as spi\n",
    "import numpy as np\n",
    "\n",
    "def sample_grid_using_scipy(x,y,grdfile):\n",
    "    \n",
    "    data=netcdf(grdfile,'r')\n",
    "\n",
    "    try:\n",
    "        lon = np.copy(data.variables['x'][:])\n",
    "        lat = np.copy(data.variables['y'][:])\n",
    "    except:\n",
    "        lon = np.copy(data.variables['lon'][:])\n",
    "        lat = np.copy(data.variables['lat'][:])\n",
    "    \n",
    "    Zg = data.variables['z'][:]\n",
    "        \n",
    "    test = fill_ndimage(Zg)\n",
    "    \n",
    "    lut=spi.RectBivariateSpline(lon,lat,test.T)\n",
    "    result = []\n",
    "    for xi,yi in zip(x,y):\n",
    "        result.append(lut(xi, yi)[0][0])\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "\n",
    "def fill_ndimage(data,invalid=None):\n",
    "    \"\"\"Replace the value of invalid 'data' cells (indicated by 'invalid')\n",
    "    by the value of the nearest valid data cell\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: numpy array of any dimension\n",
    "    invalid: a binary array of same shape as 'data'. True cells set where data\n",
    "    value should be replaced.\n",
    "    If None (default), use: invalid = np.isnan(data)\n",
    "    Returns\n",
    "    -------\n",
    "    Return a filled array.\n",
    "    Credits\n",
    "    -------\n",
    "    http://stackoverflow.com/a/9262129\n",
    "    \"\"\"\n",
    "    if invalid is None: invalid = np.isnan(data)\n",
    "    ind = nd.distance_transform_edt(invalid, return_distances=False, return_indices=True)\n",
    "    return data[tuple(ind)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract subduction zone statistics\n",
    "# Each element of this list will be a tuple of values for a specific reconstruction time.\n",
    "output_data = []\n",
    "\n",
    "# Create an empty dataframe to concatenate results to\n",
    "df_AllTimes = pd.DataFrame()\n",
    "\n",
    "# Reconstruction times.\n",
    "reconstruction_times = np.arange(min_time, max_time, time_step)\n",
    "    \n",
    "# Iterate over time steps\n",
    "for reconstruction_time in reconstruction_times:\n",
    "    print (reconstruction_time)\n",
    "    # Use existing subduction convergence script to generate sample points along subduction zones at 'time'.\n",
    "    subduction_data = []\n",
    "    subduction_convergence_data = subduction_convergence.subduction_convergence(\n",
    "                rotation_model,\n",
    "                topology_filenames,\n",
    "                tessellation_threshold_radians,\n",
    "                reconstruction_time)\n",
    "    \n",
    "    # Determine paleo raster filename.\n",
    "    raster_filename = '{0}_{1}.{2}'.format(raster_filename_base, reconstruction_time, raster_filename_ext)\n",
    "    \n",
    "    # decompress newer GMT 5 grids\n",
    "    grdDir=\"/Users/ajy321/PhD_work/SeaLevel/SeaLevel_MS/GPlatesFiles/AgeGrids/\"\n",
    "    grdCLASSIC=grdDir+\"agegrid_masked_%s.nc\" %(reconstruction_time)\n",
    "    \n",
    "    if not os.path.isfile(grdCLASSIC):\n",
    "        cmd=\"grdsample %s -R0/360/-90/90 -I0.1d -G%s --IO_NC4_CHUNK_SIZE=classic\" %(raster_filename, grdCLASSIC)\n",
    "        print (cmd)\n",
    "        os.system(cmd)\n",
    "    \n",
    "    # Sample raster/grid at subduction points.\n",
    "    subduction_lons = [data[0] for data in subduction_convergence_data]\n",
    "    subduction_lats = [data[1] for data in subduction_convergence_data]\n",
    "    conv_rate = [data[2] for data in subduction_convergence_data]\n",
    "    conv_obliq = [data[3] for data in subduction_convergence_data]\n",
    "    arc_length = [data[6] for data in subduction_convergence_data]\n",
    "    plate_age = sample_grid_using_scipy(subduction_lons, subduction_lats, grdCLASSIC)\n",
    "\n",
    "    # Make a flat list of subduction stats to input into the proximity test\n",
    "    df = pd.DataFrame({'lon' : subduction_lons, 'lat': subduction_lats,\n",
    "                      'conv_obliq' : conv_obliq, 'conv_rate' : conv_rate, 'arc_length' : arc_length,\n",
    "                      'plate_age' : plate_age, 'reconstruction_time' : reconstruction_time})\n",
    "    \n",
    "    # append dataframe \n",
    "    df_AllTimes = df_AllTimes.append(df)\n",
    "\n",
    "# export data\n",
    "df_AllTimes.to_csv(workDir+'/szData_summaryStats_%s.csv' %(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright (C) 2017 The University of Sydney, Australia\n",
    "This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License, version 2, as published by the Free Software Foundation.\n",
    "\n",
    "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License along with this program; if not, write to Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n",
    "\n",
    "Author: John Cannon\n",
    "\n",
    "## Calculate average seafloor spreading rates of mid-ocean ridges over a sliding time window (over time)\n",
    "The output file contains the following columns:\n",
    "\n",
    " reconstruction_time (Ma)\n",
    " total ridge length in metres (excluding transform segments)\n",
    " average spreading rate in cm/year (over 'averaging_time_window' million years)\n",
    " standard deviation of spreading rate in cm/year (over 'averaging_time_window' million years)\n",
    "\n",
    "The spreading rates are only calculated along ridge sections (transform sections are excluded). Note that this algorithm only works well under the following conditions:\n",
    "\n",
    "    - ridge segments are perpendicular to their spreading directions\n",
    "    - isochron geometries are up-to-date with respect to the rotation model\n",
    "            -ie, stage pole is in correct location relative to geometry\n",
    "    -there are valid rotations (in rotation model) for each isochron at its birth time plus one\n",
    "            -ie, 1My prior to isochron birth time\n",
    "    -all isochrons have conjugate plate IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreading_feature_types = [pygplates.FeatureType.gpml_mid_ocean_ridge]\n",
    "threshold_sampling_distance_radians = math.radians(0.5)\n",
    "\n",
    "# Create an empty dataframe to concatenate results to\n",
    "MORData_df = pd.DataFrame()\n",
    "\n",
    "print('Calculating spreading rates from {0} to {1} Ma...'.format(min_time, max_time))\n",
    "\n",
    "# Each element of this list will be a tuple of values for a specific reconstruction time.\n",
    "output_data = []\n",
    "\n",
    "# Read the topology filenames once instead of at every time step.\n",
    "topology_features = []\n",
    "for topology_filename in topology_filenames:\n",
    "    topology_features.extend(pygplates.FeatureCollection(topology_filename))\n",
    "\n",
    "# Keep track of spreading-rate-related quantities over time so can later calculate statistics.\n",
    "total_length_metres_time_sequence = []\n",
    "total_spreading_rate_times_length_time_sequence = []\n",
    "total_spreading_rate_squared_times_length_time_sequence = []\n",
    "\n",
    "# Iterate over times in inclusive range [min_time, max_time + averaging_time_window - 1].\n",
    "for reconstruction_time in range(min_time, max_time, time_step):\n",
    "    \n",
    "    # Use existing ridge spreading rate script to generate sample points along mid-ocean ridges at 'time'.\n",
    "    ridge_spreading_rate_data = ridge_spreading_rate.spreading_rates(\n",
    "        rotation_model,\n",
    "        topology_features,\n",
    "        reconstruction_time,\n",
    "        threshold_sampling_distance_radians,\n",
    "        spreading_feature_types)\n",
    "    \n",
    "    # Sample at ridge points.\n",
    "    ridge_lons = [data[0] for data in ridge_spreading_rate_data]\n",
    "    ridge_lats = [data[1] for data in ridge_spreading_rate_data]\n",
    "    spreading_rate = [data[2] for data in ridge_spreading_rate_data]\n",
    "    arc_length = [data[3] for data in ridge_spreading_rate_data]\n",
    "    \n",
    "    # Make a flat list of subduction stats to input into the proximity test\n",
    "    df = pd.DataFrame({'lon' : ridge_lons, 'lat': ridge_lats,\n",
    "                      'spreading_rate' : spreading_rate, 'arc_length' : arc_length,\n",
    "                      'reconstruction_time' : reconstruction_time})\n",
    "    # append dataframe \n",
    "    MORData_df = MORData_df.append(df)        \n",
    "    \n",
    "MORData_df.to_csv(workDir+'/morData_summaryStats_%s.csv' %(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
