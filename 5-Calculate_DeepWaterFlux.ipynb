{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License, version 2, as published by the Free Software Foundation.\n",
    "\n",
    "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
    "\n",
    "Author: Alexander Young\n",
    "\n",
    "### This notebook uses the work flow of Karlsen el al., (2019) to take the files created from 4-Make_SubZone_and_MOR_stats.ipynb and calculate regassing and degassing flux from subduction zone and mor kinematics\n",
    "\n",
    "##### Input:\n",
    "file of time-dependent subduction zone kinematics and plate ages e.g. szData_summaryStats_NNRPlateModel.csv\n",
    "\n",
    "file of  time-dependent mor kinematics e.g. morData_summaryStats_NNRPlateModel.csv\n",
    "\n",
    "##### Output:\n",
    "re- and degassing flux data files e.g. degassingFlux_AllTimes_NNRPlateModel.csv\n",
    "\n",
    "total time-dependent mantle-ocean water exhange file e.g. NNRPlateModel_RD_DeepWaterFlux_AllTimes.csv\n",
    "\n",
    "##### Citations:\n",
    "Karlsen, K. S., Conrad, C. P., and Magni, V., 2019, Deep Water Cycling and Sea Level Change Since the Breakup of Pangea: Geochemistry, Geophysics, Geosystems.\n",
    "\n",
    "Steinberger, B., and Becker, T. W., 2018, A comparison of lithospheric thickness models: Tectonophysics, v. 746, p. 325-338."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import gridspec\n",
    "import scipy.stats as ss\n",
    "import glob\n",
    "\n",
    "# allow plots to appear within the notebook\n",
    "% matplotlib inline\n",
    "\n",
    "min_time = 0\n",
    "max_time = 580\n",
    "time_step = 20\n",
    "\n",
    "# set model name; should be the same as in 4-Make_SubZone_and_MOR_stats.ipynb\n",
    "model='NNRPlateModel'\n",
    "\n",
    "# Set regassing parameterization per Karlsen et al., (2019)\n",
    "# 0 for RD: regassing dominated\n",
    "# 1 for LB: longterm balance\n",
    "Regassing_parameterization=1.\n",
    "\n",
    "# set working directory and make if it does not exist\n",
    "workDir=\"/Users/ajy321/PhD_work/SeaLevel/SeaLevel_MS/PythonNotebooks/DeepwaterCycling\"\n",
    "if not os.path.exists(workDir):\n",
    "    os.makedirs(workDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Calculate regassing flux\n",
    "# read in file of time-dependent subduction zone kinematics and plate ages made using 4-Make_SubZone_and_MOR_stats.ipynb\n",
    "# e.g. szData_summaryStats_NNRPlateModel.csv\n",
    "df_AllTimes = pd.read_csv(workDir+'/szData_summaryStats_%s.csv' %(model)) \n",
    "\n",
    "# drop segment if convergence rate is less than 2 cm/yr or if plate age is less than zero\n",
    "df_AllTimes = df_AllTimes[df_AllTimes.conv_rate >= 0.2]\n",
    "df_AllTimes = df_AllTimes[df_AllTimes.plate_age >= 0.0]\n",
    "\n",
    "# constrain plate age upper limit to 120 Myr\n",
    "df_AllTimes['plate_age'] = np.where(df_AllTimes['plate_age'] >= 120.0, 120., df_AllTimes['plate_age'])\n",
    "\n",
    "############################################################################################################\n",
    "# Below we calculate the orthogonal migration and convergence rates, which are important to get true estimates of area and volume flux\n",
    "\n",
    "cr = np.asarray(df_AllTimes['conv_rate'])\n",
    "co = np.asarray(df_AllTimes['conv_obliq'])\n",
    "\n",
    "df_AllTimes['ortho_conv_rate'] = pd.Series(cr*np.abs(np.cos(np.radians(co))), index=df_AllTimes.index)\n",
    "\n",
    "# Convert conv rate to m/sec\n",
    "def convR(row):\n",
    "    return ((row['conv_rate']) / 3.154e9)\n",
    "df_AllTimes['conv_rate_m']=df_AllTimes.apply(convR, axis=1)    \n",
    "\n",
    "# Convert conv rate to m/sec\n",
    "def convR(row):\n",
    "    return ((row['ortho_conv_rate']) / 3.154e9)\n",
    "df_AllTimes['ortho_conv_rate_m']=df_AllTimes.apply(convR, axis=1)    \n",
    "\n",
    "# Calculate lithosphere thickness using half space method\n",
    "def litho_thickness(row):\n",
    "    return ((10.*np.sqrt(row['plate_age']))*1000.)\n",
    "df_AllTimes['litho_thickness_m']=df_AllTimes.apply(litho_thickness, axis=1)    \n",
    "\n",
    "# convert arc length to m\n",
    "def AngularConversion(row):\n",
    "    return 2*math.pi*6371000.*((np.asarray(row['arc_length']))/360.)\n",
    "df_AllTimes['arc_length_m']=df_AllTimes.apply(AngularConversion, axis=1)    \n",
    "\n",
    "# convert myr to s\n",
    "def TimeConversion(row):\n",
    "    return row['plate_age']*3.1536e13\n",
    "df_AllTimes['plate_age_s']=df_AllTimes.apply(TimeConversion, axis=1)    \n",
    "\n",
    "# Calculate lithosphere thickness using Steinberger et al., 2018\n",
    "def litho_thickness_bs18(row):\n",
    "    return (10. * (np.sqrt(row['plate_age'])) * 1e3)\n",
    "df_AllTimes['litho_thickness_bs18_m']=df_AllTimes.apply(litho_thickness_bs18, axis=1)    \n",
    "df_AllTimes.loc[df_AllTimes.litho_thickness_bs18_m>1e5,'litho_thickness_bs18_m'] = 1e5\n",
    "\n",
    "# Calculate thermal parameter as in Karlsen et al., (2019)\n",
    "def phi(row):\n",
    "    return ((row['ortho_conv_rate_m']) * (row['plate_age_s']))/1e4\n",
    "df_AllTimes['phi']=df_AllTimes.apply(phi, axis=1)    \n",
    "\n",
    "# Calculate subducting plates relative water retention as in Karlsen et al., (2019)\n",
    "a = -0.1\n",
    "b = 0.5\n",
    "c = 0.0023\n",
    "\n",
    "def epsilon(row):\n",
    "    return max(0.0, ((a + b * (1 - math.exp(-c * row['phi'])))))\n",
    "df_AllTimes['epsilon']=df_AllTimes.apply(epsilon, axis=1)    \n",
    "\n",
    "# Calculate deep water regassing flux as in Karlsen et al., (2019)\n",
    "rho = 3200.\n",
    "if Regassing_parameterization == 0.:\n",
    "    scenario = 'RD'# regassing dominated RD\n",
    "    ap = 2.28e-3 \n",
    "else:\n",
    "    scenario = 'LB'# Longterm balance LB\n",
    "    ap = 1.07e-3 \n",
    "\n",
    "def Regassing_bs18(row):\n",
    "    return ((ap * row['epsilon'] * rho * row['litho_thickness_bs18_m'] * row['ortho_conv_rate_m'] * row['arc_length_m']) * 3.154e7)\n",
    "df_AllTimes['R_t_bs18']=df_AllTimes.apply(Regassing_bs18, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time-dependent regassing flux\n",
    "regassing_bs18 = []\n",
    "total_length = []\n",
    "average_velocity = []\n",
    "average_ortho_velocity = []\n",
    "mean_age = []\n",
    "epsilon = []\n",
    "phi = []\n",
    "mean_thickness =[]\n",
    "\n",
    "TimeStepList = np.arange(min_time, max_time, time_step)\n",
    "\n",
    "for TIME in TimeStepList:\n",
    "    subset = df_AllTimes[(df_AllTimes['reconstruction_time']>=TIME) & (df_AllTimes['reconstruction_time']<(TIME+time_step))]\n",
    "    regassing_bs18.append(np.nansum(np.asarray(subset.R_t_bs18)))\n",
    "    total_length.append(np.nansum(np.asarray(subset.arc_length_m)))\n",
    "    average_velocity.append(subset['conv_rate'].mean())\n",
    "    average_ortho_velocity.append(subset['ortho_conv_rate'].mean())\n",
    "    mean_age.append(subset['plate_age'].mean())\n",
    "    mean_thickness.append(subset['litho_thickness_bs18_m'].mean())\n",
    "\n",
    "    epsilon.append(subset['epsilon'].mean())\n",
    "    phi.append(subset['phi'].mean())\n",
    "\n",
    "regassing_df = pd.DataFrame({'Time':TimeStepList, 'regassing_bs18':regassing_bs18, 'sz_total_length':total_length,\n",
    "                             'sz_average_velocity':average_velocity, 'average_ortho_velocity':average_ortho_velocity,\n",
    "                             'mean_age':mean_age, 'mean_thickness':mean_thickness, 'epsilon':epsilon, 'phi':phi})\n",
    "\n",
    "regassing_df.to_csv(workDir+'/regassingFlux_AllTimes_%s_%s.csv' %(model, scenario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajy321/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/ajy321/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/ajy321/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# -- Calculate degassing flux \n",
    "# read in file of time-dependent mor kinematics made using 4-Make_SubZone_and_MOR_stats.ipynb\n",
    "# e.g. morData_summaryStats_NNRPlateModel.csv\n",
    "MORData_df = pd.read_csv(workDir+'/morData_summaryStats_%s.csv' %(model)) \n",
    "\n",
    "# remove segments where mor velocity is less than 2 cm/yr\n",
    "MORdf_AllTimes = MORData_df[MORData_df.spreading_rate >= 0.2]\n",
    "\n",
    "# convert arc length to m\n",
    "def AngularConversion(row):\n",
    "    return 2*math.pi*6371000.*((np.asarray(row['arc_length']))/360.)\n",
    "MORdf_AllTimes['arc_length_m']=MORdf_AllTimes.apply(AngularConversion, axis=1)    \n",
    "\n",
    "# Convert spreadingrate to m\n",
    "def spr_rate(row):\n",
    "    return ((row['spreading_rate']) / 100.)\n",
    "MORdf_AllTimes['spreading_rate_m']=MORdf_AllTimes.apply(spr_rate, axis=1)    \n",
    "\n",
    "# calculate degassing as in Karlsen et al., (2019)\n",
    "def Degassing(row):\n",
    "    gamma = 3.15e-3\n",
    "    h = 7000.\n",
    "    return ((gamma) * (rho) * (h) * (row['spreading_rate_m']) * (row['arc_length_m']))\n",
    "\n",
    "MORdf_AllTimes['D_t']=MORdf_AllTimes.apply(Degassing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time-dependent degassing flux\n",
    "degassing = []\n",
    "total_length = []\n",
    "average_velocity = []\n",
    "\n",
    "for TIME in TimeStepList:\n",
    "    subset1 = MORdf_AllTimes[(MORdf_AllTimes['reconstruction_time']==TIME)]\n",
    "    degassing.append(math.fsum(subset1.D_t))    \n",
    "    total_length.append(math.fsum(np.asarray(subset1.arc_length_m)))\n",
    "    average_velocity.append(subset1['spreading_rate'].mean())\n",
    "\n",
    "degassing_df = pd.DataFrame({'Time':TimeStepList,'degassing':degassing, 'mor_total_length':total_length,\n",
    "                            'mor_average_velocity':average_velocity})\n",
    "\n",
    "def invert(row):\n",
    "    return row['degassing'] * -1.\n",
    "degassing_df['degassing']=degassing_df.apply(invert, axis=1)    \n",
    "\n",
    "degassing_df.to_csv(workDir+'/degassingFlux_AllTimes_%s.csv' %(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- calculate deep water flux \n",
    "# -- combine regassing and degassing dataframes\n",
    "dfFINAL = pd.merge(degassing_df, regassing_df, on='Time', how='outer')\n",
    "\n",
    "# convert degassing and regassing data to array\n",
    "degassing=np.array(dfFINAL['degassing'])\n",
    "regassing=np.array(dfFINAL['regassing_bs18'])\n",
    "\n",
    "dt = 20e6 # Myear time step\n",
    "    \n",
    "# calculate net water flux and integrate over time\n",
    "height = (degassing+regassing) / 1000.\n",
    "mheight = np.zeros(height.shape)\n",
    "mheight[1:] = [(height[i]+height[i-1])/2.0 for i in range(1,len(height))]\n",
    "dfFINAL['volume_m3'] = np.cumsum(mheight*dt)\n",
    "\n",
    "# export to file\n",
    "dfFINAL.to_csv(workDir+'/%s_%s_DeepWaterFlux_AllTimes.csv' %(model, scenario))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
