{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License, version 2, as published by the Free Software Foundation.\n",
    "\n",
    "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
    "\n",
    "Author: Alexander Young and Nicolas Flament\n",
    "\n",
    "### This notebook takes time-dependent hypsometry curves and modifies them for dyanmic topography. The present day ocean basin water volume calculated from the curve at time = 0 Ma is then modified for relative adjustments to submarine sediment and OLIP volumes, trench volume and deep water flux volume. The adjusted volume is then used to flood the hypsometry curve and sea level is calculated.\n",
    "\n",
    "##### Input:\n",
    "time-dependent trench volumes produced from 1_SeafloorBathymetry_from_AgeGrids_and_TrenchVolume.ipynb e.g. C1TT_sz_300_km_normalised_volume_trench_age.dat\n",
    "\n",
    "time-dependent sediment thickness produced from 2-Sediment_thickness_model.ipynb e.g. SedModelFinal_0.0-580.0Ma_500km_Clipped5km.csv\n",
    "\n",
    "time-dependent OLIP volumes produced from 3-Volumes_of_submarine_LIPs.ipynb e.g. Model_volumes_of_submarine_LIPs.csv\n",
    "\n",
    "time-dependent deep water flux produced from 5-Calculate_DeepWaterFlux.ipynb e.g. NNRPlateModel_RD_DeepWaterFlux_AllTimes.csv\n",
    "\n",
    "time-dependent dynamic topographys produced from 7-Calc_Air_Loaded_DT.ipynb e.g. C1_mean_TopoCheck_ocean_age_grid_AL.dat\n",
    "\n",
    "time-dependent hypsometry models produced from 6-Model_timedependent_AL_hypsometry.ipynb e.g. hypsoModel_HypsoModelFinal_0Ma_fOA_fS_KRCC.csv\n",
    "\n",
    "##### Output:\n",
    "time-dependent sea level file e.g. C1_0-500Ma_SeaLevelFinal_sedClipped_fOA_fS_KRCC.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/ajy321/pygplates_rev18_python27_MacOS64')\n",
    "import pygplates\n",
    "# Add directory containing the 'ptt' module (Plate Tectonic Tools) to the Python path.\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as spi\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from numpy import ones,vstack\n",
    "from numpy.linalg import lstsq\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Define the time range.\n",
    "# The reconstruction time range (topologies resolved to these times).\n",
    "# Also used to get paleo raster filenames based on 'raster_filename_base'.\n",
    "min_time = 0\n",
    "max_time = 600\n",
    "time_step = 100\n",
    "\n",
    "# define geodynamic model\n",
    "model='gld428'\n",
    "\n",
    "# Toggle dynamicOceanArea to call model for dynamic or static ocean basin area.\n",
    "# 1 dynamic, 0 fixed\n",
    "dynamicOceanArea = 0.\n",
    "\n",
    "# Toggle dynamicSlope to to call model for dynamic or static coastal gradient.\n",
    "# 1 dynamic, 0 fixed\n",
    "dynamicSlope = 0.\n",
    "\n",
    "# Toggle age_depth_model to call model for half space cooling or simple plate.\n",
    "# 0 simple plate, 1 half space cooling, 2 complex\n",
    "age_depth_model = 0.\n",
    "\n",
    "# Toggle dynamic topography\n",
    "# 1 No Dt, 0 include Dt\n",
    "DT = 0.\n",
    "\n",
    "# write program to search for number and return index\n",
    "def find_nearest(array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return array[idx]\n",
    "\n",
    "resample_list=np.arange(0.0, 1.0, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- load Hypsometric curve for etopo1 produced by Eakins et al., 2012\n",
    "# -- set output file names \n",
    "etopoHistFile=\"/Users/ajy321/PhD_work/SeaLevel/USYDmodel/DependentInputs/etopo1_hyp_curve.dat\"\n",
    "etopoHist = pd.read_csv(etopoHistFile, skiprows=1, names=['ELEVATION', 'Area_per'],\n",
    "                        delim_whitespace=True, usecols=['ELEVATION', 'Area_per'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age is:  0.0 Ma\n",
      "Sea level at 0 Ma is 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajy321/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:308: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age is:  20.0 Ma\n",
      "Sea level at 20 Ma is 39\n",
      "Age is:  40.0 Ma\n",
      "Sea level at 40 Ma is 57\n",
      "Age is:  60.0 Ma\n",
      "Sea level at 60 Ma is 65\n",
      "Age is:  80.0 Ma\n",
      "Sea level at 80 Ma is 94\n",
      "Age is:  100.0 Ma\n",
      "Sea level at 100 Ma is 106\n",
      "Age is:  120.0 Ma\n",
      "Sea level at 120 Ma is 118\n",
      "Age is:  140.0 Ma\n",
      "Sea level at 140 Ma is 65\n",
      "Age is:  160.0 Ma\n",
      "Sea level at 160 Ma is -38\n",
      "Age is:  180.0 Ma\n",
      "Sea level at 180 Ma is -6\n",
      "Age is:  200.0 Ma\n",
      "Sea level at 200 Ma is 1\n",
      "Age is:  220.0 Ma\n",
      "Sea level at 220 Ma is 0\n",
      "Age is:  240.0 Ma\n",
      "Sea level at 240 Ma is 0\n",
      "Age is:  260.0 Ma\n",
      "Sea level at 260 Ma is 160\n",
      "Age is:  280.0 Ma\n",
      "Sea level at 280 Ma is 174\n",
      "Age is:  300.0 Ma\n",
      "Sea level at 300 Ma is 302\n",
      "Age is:  320.0 Ma\n",
      "Sea level at 320 Ma is 380\n",
      "Age is:  340.0 Ma\n",
      "Sea level at 340 Ma is 385\n",
      "Age is:  360.0 Ma\n",
      "Sea level at 360 Ma is 458\n",
      "Age is:  380.0 Ma\n",
      "Sea level at 380 Ma is 453\n",
      "Age is:  400.0 Ma\n",
      "Sea level at 400 Ma is 445\n",
      "Age is:  420.0 Ma\n",
      "Sea level at 420 Ma is 204\n",
      "Age is:  440.0 Ma\n",
      "Sea level at 440 Ma is 245\n",
      "Age is:  460.0 Ma\n",
      "Sea level at 460 Ma is 401\n",
      "Age is:  480.0 Ma\n",
      "Sea level at 480 Ma is 285\n",
      "Age is:  500.0 Ma\n",
      "Sea level at 500 Ma is 340\n",
      "Age is:  520.0 Ma\n",
      "Sea level at 520 Ma is 370\n",
      "Age is:  540.0 Ma\n",
      "Sea level at 540 Ma is 273\n",
      "Age is:  560.0 Ma\n",
      "Sea level at 560 Ma is 123\n"
     ]
    }
   ],
   "source": [
    "# Load in DT model\n",
    "# Path to modeled dynamic topography\n",
    "dtDir = '/Users/ajy321/PhD_work/SeaLevel/NF_workflows/Average_dynamic_elevation/gld428/Topo'\n",
    "contDTdf = pd.read_csv(dtDir+'/%s_mean_TopoCheck_conts_age_grid_AL.dat' %(model),\n",
    "                       delimiter = \" \", header=None, names=['Age', 'contDT'])\n",
    "oceanicDTdf = pd.read_csv(dtDir+'/%s_mean_TopoCheck_ocean_age_grid_AL.dat'%(model),\n",
    "                          delimiter = \" \", header=None, names=['Age', 'oceanicDT'])\n",
    "oceanAreadf = pd.read_csv('/Users/ajy321/PhD_work/SeaLevel/NF_workflows/Average_dynamic_elevation/gld428/Topo/gld428_OceanArea.dat',\n",
    "                          delimiter = \" \", header=None, names=['Age', 'Area_m'])\n",
    "\n",
    "# Designate present day continental and oceanic DT\n",
    "contpd = float(contDTdf['contDT'].iloc[-1])\n",
    "oceanpd = float(oceanicDTdf['oceanicDT'].iloc[-1])\n",
    "\n",
    "# Calibrate continental and oceanic DT wrt to present day\n",
    "contDTdf ['contDT'] -= contpd\n",
    "oceanicDTdf ['oceanicDT'] -= oceanpd\n",
    "\n",
    "# make and empty list to populate new sea levels to\n",
    "target_vol_list=[]\n",
    "result_vol_list=[]\n",
    "SL_elev_list=[]\n",
    "Vsed_list=[]\n",
    "Vlip_list=[]\n",
    "deepH20_list=[]\n",
    "meanDepth = []\n",
    "midDepth = []\n",
    "contFlooding = []\n",
    "baseShelf = []\n",
    "dt_list = []\n",
    "\n",
    "# Iterate over time steps\n",
    "reconstruction_times = np.arange(min_time, max_time, time_step)\n",
    "for reconstruction_time in reconstruction_times:\n",
    "    print (\"Age is: \",round(reconstruction_time, 1), \"Ma\")\n",
    "        \n",
    "    #Define cooling model\n",
    "    if dynamicOceanArea == 1.:\n",
    "        OAname = 'dOA'\n",
    "    else:\n",
    "        OAname = 'fOA'\n",
    "\n",
    "    if dynamicSlope == 1.:\n",
    "        Sname = 'dS'\n",
    "    else:\n",
    "        Sname = 'fS'\n",
    "        \n",
    "    if age_depth_model == 1.:\n",
    "        coolingModel = 'HSCk'\n",
    "        dmax = -1656. # this is a little bit greater than Zr to ensure the clip occurs beyond the continental shelf\n",
    "    elif age_depth_model == 0.:\n",
    "        coolingModel = 'Pk'\n",
    "        dmax = -2216. # this is a little bit greater than Zr to ensure the clip occurs beyond the continental shelf\n",
    "    else:\n",
    "        coolingModel = 'KRCC'\n",
    "        dmax = -2500. # this is a little bit greater than Zr to ensure the clip occurs beyond the continental shelf\n",
    "        \n",
    "    # Load air loaded hypsometry curve\n",
    "    hypsoFile=\"/Users/ajy321/PhD_work/SeaLevel/Hypsometry/ModelAncientContHypso/gld428_0-560Ma_ModeledHypsometry_AL_fOA_fS_%s/gld428_HypsoModelFinal_%sMa_fOA_fS_%s.csv\" %(coolingModel, reconstruction_time, coolingModel)\n",
    "    hypsodf = pd.read_csv(hypsoFile, header=None, names=['Area_per', 'ELEVATION'])\n",
    "    \n",
    "    #increase spatial resolution of curve\n",
    "    resampledf = pd.DataFrame({'Area_per':resample_list})\n",
    "    hypso_hidef = pd.merge(resampledf, hypsodf, on='Area_per', how='outer')\n",
    "    hypso_hidef = hypso_hidef.sort_values(by='Area_per', ascending=True)\n",
    "    hypso_hidef = hypso_hidef.interpolate(method='linear', axis=0, limit=None, limit_direction='both').ffill().bfill()\n",
    "    hypso_hidef['Area_m'] = hypso_hidef['Area_per'] * 5.1e14\n",
    "    \n",
    "    # set model dependent Acc (cum area at ridge depth)\n",
    "    Acc = 0.407837 # present day ocean area\n",
    "    \n",
    "    # set model dependent Ash (cum area at base of the continental shelf; -250m)\n",
    "    Zsh=-250.\n",
    "    index_loc_Ash = abs(hypso_hidef['ELEVATION'] - Zsh).idxmin()\n",
    "    Ash = float(hypso_hidef['Area_per'].iloc[index_loc_Ash])\n",
    "    \n",
    "    # set model dependent sea level area. \n",
    "    Zsl = 0.\n",
    "    index_loc_SL = abs(hypso_hidef['ELEVATION'] - Zsl).idxmin()\n",
    "    SL = float(hypso_hidef['Area_per'].iloc[index_loc_SL])\n",
    "    \n",
    "    # set model dependent Af (cum area at top of the continental shelf; 200m)\n",
    "    Ztop=200.\n",
    "    index_loc_Af = abs(hypso_hidef['ELEVATION'] - Ztop).idxmin()\n",
    "    Af = float(hypso_hidef['Area_per'].iloc[index_loc_Af])\n",
    "    \n",
    "    # calculate volume above ridge from !*! AIR LOADED !*! bathy grid\n",
    "    # set variables to unload bathy\n",
    "    rhom = 3340. # mantle density\n",
    "    rhow = 1030. # water density\n",
    "    rhoa = 1. # air density\n",
    "    waterLoad = (rhoa - rhom) / (rhow - rhom)\n",
    "    waterUnload = (1/waterLoad)\n",
    "    iso = ((rhom - rhow)/rhom)\n",
    "    \n",
    "    # Earth Area\n",
    "    AE = 5.1e14\n",
    "    \n",
    "    # Extract oceanic area\n",
    "    OArea=(oceanAreadf.loc[oceanAreadf['Age'] == reconstruction_time, 'Area_m'].item())\n",
    "#     print ('ocean area is', OArea)\n",
    "    CArea = (AE - OArea)\n",
    "    CAreaWeight = CArea/OArea\n",
    "\n",
    "    # Add DT if required\n",
    "    if DT == 1:\n",
    "        hypso_hidef['ELEVATION_DT'] = hypso_hidef['ELEVATION']\n",
    "        oceanicDT = 0.0\n",
    "        contDT = 0.0\n",
    "    else:\n",
    "        # add air loaded DT\n",
    "        oceanicDT=(oceanicDTdf.loc[oceanicDTdf['Age'] == reconstruction_time, 'oceanicDT'].item())\n",
    "        contDT=(contDTdf.loc[contDTdf['Age'] == reconstruction_time, 'contDT'].item())\n",
    "        DT_t = oceanicDT - (contDT * CAreaWeight)\n",
    "        hypso_hidef.loc[hypso_hidef.Area_per >= Acc, 'ELEVATION_DT'] = hypso_hidef.ELEVATION + (DT_t)\n",
    "        hypso_hidef.loc[hypso_hidef.Area_per < Acc, 'ELEVATION_DT'] = hypso_hidef.ELEVATION\n",
    "        dt_list.append(DT_t)\n",
    "        \n",
    "    # split the hypso curve at the top (4000m) to calculate max volume, at the and base (-4000m) to calculate minimum volume\n",
    "    # and at SL (0m) to calculate present day volume\n",
    "    hypso_min = hypso_hidef.drop(hypso_hidef[hypso_hidef.ELEVATION_DT > -1000.].index)\n",
    "    hypso_max = hypso_hidef.drop(hypso_hidef[hypso_hidef.ELEVATION_DT > 11000.].index)\n",
    "    hypso_target = hypso_hidef.drop(hypso_hidef[hypso_hidef.ELEVATION_DT > Zsl].index)\n",
    "    \n",
    "    # make all values negative so we can waterload\n",
    "    hypso_min[\"all_negative\"] = (hypso_min[\"ELEVATION_DT\"] - hypso_min[\"ELEVATION_DT\"].iloc[0])\n",
    "    hypso_max[\"all_negative\"] = (hypso_max[\"ELEVATION_DT\"] - hypso_max[\"ELEVATION_DT\"].iloc[0])\n",
    "    hypso_target[\"all_negative\"] = (hypso_target[\"ELEVATION_DT\"] - hypso_target[\"ELEVATION_DT\"].iloc[0])\n",
    "\n",
    "    # now water load\n",
    "    hypso_min[\"ELEVATION_WL\"] = hypso_min[\"all_negative\"] * waterLoad \n",
    "    hypso_max[\"ELEVATION_WL\"] = hypso_max[\"all_negative\"] * waterLoad \n",
    "    hypso_target[\"ELEVATION_WL\"] = hypso_target[\"all_negative\"] * waterLoad\n",
    "\n",
    "    # make all values positive so we can calculate area above the curve\n",
    "    hypso_min[\"all_positive\"] = hypso_min[\"ELEVATION_WL\"] - float(hypso_min['ELEVATION_WL'].iloc[-1])\n",
    "    hypso_max[\"all_positive\"] = hypso_max[\"ELEVATION_WL\"] - float(hypso_max['ELEVATION_WL'].iloc[-1])\n",
    "    hypso_target[\"all_positive\"] = hypso_target[\"ELEVATION_WL\"] - float(hypso_target['ELEVATION_WL'].iloc[-1])\n",
    "\n",
    "    # add datum column to dataframe so we can calculate area above the curve\n",
    "    hypso_min['Zsh_min']= (0 + float(hypso_min['all_positive'].iloc[0]))\n",
    "    hypso_max['Ztop_max']= (0 + float(hypso_max['all_positive'].iloc[0]))\n",
    "    hypso_target['Z_sL']= (0 + float(hypso_target['all_positive'].iloc[0]))\n",
    "    \n",
    "    # find difference between datum and hypso curve\n",
    "    diff_min = hypso_min['Zsh_min'].values - hypso_min['all_positive'].values\n",
    "    diff_max = hypso_max['Ztop_max'].values - hypso_max['all_positive'].values\n",
    "    diff_target = hypso_target['Z_sL'].values - hypso_target['all_positive'].values\n",
    "    \n",
    "    # caluculate volume betwen the datum and the hypso curve\n",
    "    volume_min = np.trapz(diff_min, hypso_min['Area_m'].values)\n",
    "    volume_max = np.trapz(diff_max, hypso_max['Area_m'].values)\n",
    "    volume_target = np.trapz(diff_target, hypso_target['Area_m'].values)\n",
    "    target_vol_list.append(volume_target)\n",
    "\n",
    "    # Load in sediment thickness model\n",
    "    sedFile=\"/Users/ajy321/PhD_work/SeaLevel/SedimentThickness/SedModelFinal_0-580Ma_400km.csv\"\n",
    "    seddf = pd.read_csv(sedFile)\n",
    "    # calculate the compoent of volume displaced by the sediments\n",
    "    seddf[\"seds_wrt_pd\"] = seddf[\"mean_thicknes\"] - float(seddf['mean_thicknes'].iloc[0])\n",
    "    Vsed = ((1. - Acc) * AE) * (seddf.loc[seddf['Age'] == reconstruction_time, 'seds_wrt_pd'].item() * 1000.)\n",
    "    Vsed_list.append(Vsed)\n",
    "    \n",
    "    # Load in LIP volume model\n",
    "    LIPFile=\"/Users/ajy321/PhD_work/SeaLevel/USYDmodel/OLIPModel/Model_volumes_of_submarine_LIPs.csv\"\n",
    "    LIPdf = pd.read_csv(LIPFile)\n",
    "    # calculate the compoent of volume displaced by the LIPs\n",
    "    LIPdf[\"Lip_wrt_pd\"] = LIPdf[\"50per\"] - float(LIPdf['50per'].iloc[0])\n",
    "    Vlip = (LIPdf.loc[LIPdf['Age'] == reconstruction_time, 'Lip_wrt_pd'].item())\n",
    "    Vlip_list.append(Vlip)\n",
    "    \n",
    "    # Load deep water recycling model\n",
    "    deepwaterFile=\"/Users/ajy321/PhD_work/SeaLevel/SeaLevel_MS/PythonNotebooks/DeepwaterCycling/NNRPlateModel_RD_DeepWaterFlux_AllTimes.csv\"\n",
    "    deepwaterdf = pd.read_csv(deepwaterFile)\n",
    "    deepwaterdf[\"volume_wrt_pd\"] = deepwaterdf[\"volume_m3\"] - float(deepwaterdf['volume_m3'].iloc[0])\n",
    "    # set volume of water contributed by the deep water cycle\n",
    "    Vdeepwater = (deepwaterdf.loc[deepwaterdf['Time'] == reconstruction_time, 'volume_wrt_pd'].item())\n",
    "    deepH20_list.append(Vdeepwater)\n",
    "    \n",
    "    # Load volume of trenches\n",
    "    trenchFile=\"/Users/ajy321/PhD_work/SeaLevel/BathymetryModeling/gld428_Volumes/gld428TT_sz_300_km_normalised_volume_trench_age.dat\"\n",
    "    trenchdf = pd.read_csv(trenchFile, names=['Time', 'volume_m3'], delim_whitespace=True)\n",
    "    #calibrate trench volumes with respect to present day\n",
    "    trenchdf[\"volume_wrt_pd\"] = trenchdf[\"volume_m3\"] - float(trenchdf['volume_m3'].iloc[-1])\n",
    "    # set volume of water displaced by oceanic trenches\n",
    "    Vtrench = (trenchdf.loc[trenchdf['Time'] == reconstruction_time, 'volume_wrt_pd'].item())\n",
    "    \n",
    "    # Load Stap et al. 2017 ice-volume effects on SL for the last 38 myr\n",
    "    StapFile=\"/Users/ajy321/PhD_work/SeaLevel/USYDmodel/DeBoer-et-al-2010_Glaciology.csv\"\n",
    "    Stapdf = pd.read_csv(StapFile)\n",
    "    #set volume of water sotred as glacial ice\n",
    "    Vice = ((Stapdf.loc[Stapdf['Time'] == reconstruction_time, 'ice_SLwrt'].item())) * iso\n",
    "  \n",
    "    # Set minimum volume\n",
    "    Vmin = (volume_min)\n",
    "\n",
    "    # Set maximum volume\n",
    "    Vmax = (volume_max)\n",
    "     \n",
    "    # Time to flood the curve    \n",
    "    if reconstruction_time == 0.:\n",
    "        x = volume_target\n",
    "    \n",
    "    # modify present day volume with contribution volumes\n",
    "    # VoTarget = x + Vsed + Vlip - Vtrench + Vdeepwater\n",
    "    VoTarget = x + Vsed + Vlip - Vtrench + Vdeepwater\n",
    "    \n",
    "    lim=VoTarget/1e4\n",
    "    \n",
    "    # sometimes the iteration process does not converge; adding an aribtrary DC shift (_alpha)\n",
    "    # usually resolves this\n",
    "    _alpha=0.\n",
    "    \n",
    "    # iterative approach will not exactly locate VoTrue,\n",
    "    # so provide a constrained solution range here\n",
    "    # using VoMax and VoMin\n",
    "    VoMax=VoTarget+lim\n",
    "    VoMin=VoTarget-lim\n",
    "    \n",
    "    # iteration counters\n",
    "    # first iteration\n",
    "    it=0\n",
    "    \n",
    "    # maximum number of iterations\n",
    "    iterations=100\n",
    "    \n",
    "    # minimum topography value is used as a contour\n",
    "    ## the iteration process needs two values to start off, the further apart the better\n",
    "    ## cont1 and cont2 are the minimum and maximum bounds for sea level (deepest abyss and highest mountains)\n",
    "    cont1=(float(hypso_min['all_positive'].iloc[0]))\n",
    "\n",
    "    # maximum topography value is used as a contour\n",
    "    cont2=(float(hypso_max['all_positive'].iloc[0]))\n",
    "    \n",
    "    # volume below minimum contour level\n",
    "    v1_min=Vmin\n",
    "    \n",
    "    # volume contained within maximum contour\n",
    "    v2_max=Vmax\n",
    "    \n",
    "    contf=0.0\n",
    "    \n",
    "    ## contf will be the returned value. Our first guess is 0.\n",
    "    while it < iterations and contf == 0.0:\n",
    "        \n",
    "        ## ensuring that contf is within bounds throughout iterations\n",
    "        if v1_min < VoMax and v1_min > VoMin:\n",
    "            contf=cont1 + Vice\n",
    "        elif v2_max < VoMax and v2_max > VoMin:\n",
    "            contf=cont2 + Vice\n",
    "        else:\n",
    "            cont3=cont2+(1.0+_alpha)*(cont1-cont2)*(VoTarget-v2_max)/(v1_min-v2_max)\n",
    "            if cont3 == cont2:\n",
    "                contf=cont2 + Vice\n",
    "        ## ensuring that contf is within bounds throughout iterations\n",
    "            else:\n",
    "                if cont3 > cont2:\n",
    "                    cont3=cont2\n",
    "                elif cont3 < cont1:\n",
    "                    cont3=cont1\n",
    "        ## Calculating the volume of oceans above cont3\n",
    "        # here we take the preesnt day water volume, modified for past contributions and use it to inundate \n",
    "        #the time dependent hypsometry\n",
    "                cont3 = (cont3 + Vice)\n",
    "                hypso_z3 = hypso_max.drop(hypso_max[hypso_max.all_positive > (cont3)].index)\n",
    "                hypso_z3['z3_datum']= (0 + float(hypso_z3['all_positive'].iloc[0]))\n",
    "                diff_z3 = hypso_z3['z3_datum'].values - hypso_z3['all_positive'].values\n",
    "                v3 = np.trapz(diff_z3, hypso_z3['Area_m'].values)\n",
    "                \n",
    "        ## Checking if that volume v3 meets convergence criterion\n",
    "            if v3 < VoMax and v3 > VoMin:\n",
    "                contf=(float(hypso_z3['all_positive'].iloc[0])) + Vice\n",
    "\n",
    "        ## If not updating either upper bound or lower bound\n",
    "            elif v3 > VoMax:\n",
    "                v2_max=v3\n",
    "                cont2=cont3\n",
    "            elif v3 < VoMin:\n",
    "                v1_min=v3\n",
    "                cont1=cont3\n",
    "                \n",
    "            it+=1\n",
    "            if it == iterations:\n",
    "\n",
    "                _alpha=_alpha+0.2\n",
    "                contf=(float(hypso_z3['all_positive'].iloc[0])) + Vice\n",
    "                it=0\n",
    "            if _alpha > 1.8:\n",
    "                sys.exit()\n",
    "    \n",
    "    # find present day SL to calibrate curve with respect to present\n",
    "    if reconstruction_time == 0.:\n",
    "        SL_zero = ((hypso_z3[\"ELEVATION\"].iloc[0]))\n",
    "    SL_t = ((hypso_z3[\"ELEVATION_DT\"].iloc[0] - SL_zero))    \n",
    "    result_vol_list.append(v3)\n",
    "    SL_elev_list.append(int(SL_t))\n",
    "    print (\"Sea level at\", reconstruction_time,\"Ma is\", (int(SL_t)))\n",
    "\n",
    "    # Create an empty dataframe to export hypso results to\n",
    "    export = hypso_max\n",
    "    export.loc[export.ELEVATION <= SL_t, 'hypso_WL'] = ((export['ELEVATION'] - SL_t) * waterLoad) + SL_t\n",
    "    export.loc[export.ELEVATION > SL_t, 'hypso_WL'] = export['ELEVATION']\n",
    "    export.loc[export.ELEVATION_DT <= SL_t, 'FinalELEVATION'] = ((export['ELEVATION_DT'] - SL_t) * waterLoad) + SL_t\n",
    "    export.loc[export.ELEVATION_DT > SL_t, 'FinalELEVATION'] = export['ELEVATION_DT']\n",
    "#     export.to_csv('./exportHypso_%s.csv' %(reconstruction_time))\n",
    "\n",
    "    # calculate flooded continetnal area - used for plotting.\n",
    "    array = export.as_matrix(columns=export.columns[1:2])\n",
    "    SL = np.asscalar(find_nearest(array, SL_t))\n",
    "    index_loc_0m = export.loc[export['ELEVATION'] == SL].index.tolist()\n",
    "    contFLOOD = float(export['Area_per'].iloc[index_loc_0m])\n",
    "    # append to lists\n",
    "    contFlooding.append(contFLOOD)\n",
    "    baseShelf.append(Acc)\n",
    "\n",
    "    VoTarget = 0.\n",
    "    \n",
    "SLelevdf = pd.DataFrame({'Age[Ma]':reconstruction_times, 'SL_elevation[m]':SL_elev_list,\n",
    "                        \"ocean_basin_volume\":target_vol_list,\n",
    "                        \"pd_water_volume\":result_vol_list, \"baseShelf\":baseShelf,\n",
    "                        \"contFlooding\":contFlooding,})\n",
    "\n",
    "SLelevdf['contFlooding_m^2'] = (SLelevdf['baseShelf'] - SLelevdf['contFlooding']) * AE\n",
    "SLelevdf.to_csv(\"%s_%s-%sMa_SeaLevelFinal_Basecase_%s_%s_%s.csv\" %(model, min_time, (max_time-time_step), OAname, Sname, coolingModel))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
